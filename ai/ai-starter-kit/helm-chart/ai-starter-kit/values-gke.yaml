jupyterhub:
  nameOverride: "jupyterhub"
  postgresql:
    nameOverride: "jupyterhub-postgresql"
    enabled: true
    auth:
      password: "changeme"

  singleuser:
    fsGid: 100
    defaultUrl: "/lab/tree/welcome.ipynb"
    lifecycleHooks:
      postStart: null
    image:
      tag: "5.0.0-debian-12-r2"
    initContainers:
      - name: model-initializer
        image: python:3.9-slim-bullseye
        env:
          - name: TRANSFORMERS_CACHE
            value: /tmp/models-cache
          - name: HF_HOME
            value: /tmp/models-cache
          - name: TMPDIR
            value: /tmp/models-cache
          - name: PIP_CACHE_DIR
            value: /tmp/models-cache
          - name: PIP_NO_CACHE_DIR
            value: "1"
          - name: PYTHONUSERBASE
            value: /tmp/models-cache
          - name: PYTHONUNBUFFERED
            value: "1"
          # - name: PYTHONPATH
          #   value: "/tmp/models-cache"
        command:
          - /bin/sh
          - -c
          - |
            set -e
            pip install --user --no-cache-dir -r /tmp/requirements.txt
            python /tmp/download_models.py
        volumeMounts:
          - name: requirements-txt
            mountPath: /tmp/requirements.txt
            subPath: requirements.txt
            readOnly: true
          # - name: models-cache
          #   mountPath: /tmp/models-cache
          - name: hf-download-script
            mountPath: /tmp/download_models.py
            subPath: download_models.py
            readOnly: true
          - name: hf-token-secret
            mountPath: "/etc/secrets/huggingface"
            readOnly: true
        resources:
          requests:
            cpu: "2"
            memory: 16Gi
            ephemeral-storage: 10Gi
          limits:
            cpu: "4"
            memory: 32Gi
            ephemeral-storage: 10Gi
    extraVolumes:
      - name: requirements-txt
        configMap:
          name: "{{ .Release.Name }}-requirements-txt"
      # - name: models-cache
      #   persistentVolumeClaim:
      #     claimName: "{{ .Release.Name }}-models-cache-pvc"
      - name: hf-download-script
        configMap:
          name: "{{ .Release.Name }}-hf-download-script"
      - name: welcome-notebook
        configMap:
          name: "{{ .Release.Name }}-welcome-notebook"
      - name: ray-notebook
        configMap:
          name: "{{ .Release.Name }}-ray-notebook"
      - name: hf-token-secret
        secret:
          secretName: "{{ .Release.Name }}-hf-token-secret"
          optional: true
    extraVolumeMounts:
      - name: requirements-txt
        mountPath: /tmp/requirements.txt
        subPath: requirements.txt
      # - name: models-cache
      #   mountPath: /tmp/models-cache
      - name: hf-download-script
        mountPath: /tmp/download_models.py
        subPath: download_models.py
      - name: welcome-notebook
        mountPath: /tmp/welcome.ipynb
        subPath: welcome.ipynb
      - name: ray-notebook
        mountPath: /tmp/ray.ipynb
        subPath: ray.ipynb
      - name: hf-token-secret
        mountPath: "/etc/secrets/huggingface"
        readOnly: true
    extraEnvVars:
        RAY_ADDRESS: "ray://{{ .Release.Name }}-kuberay-head-svc:10001"
        MLFLOW_TRACKING_URI: "http://{{ .Release.Name }}-mlflow:5000"
        HF_HOME: "/tmp/models-cache"
        TRANSFORMERS_CACHE: "/tmp/models-cache/"
        TMPDIR: "/tmp/models-cache/"
        PIP_CACHE_DIR: "/tmp/models-cache/"
        PYTHONUSERBASE: "/tmp/models-cache/"
        PYTHONPATH: "/tmp/models-cache/lib/python3.9/site-packages"
    resources:
      limits:
        memory: 32Gi
        ephemeral-storage: 10Gi
      requests:
        memory: 16Gi
        ephemeral-storage: 10Gi
  hub:
    password: "sneakypass"
    extraEnvVars:
        - name: "RAY_ADDRESS"
          value: "{{ .Release.Name }}-kuberay-head-svc"
        - name: "MLFLOW_TRACKING_URI"
          value: "http://{{ .Release.Name }}-mlflow-tracking"
    extraConfig:
      00-spawner-timeouts: |
        c.KubeSpawner.start_timeout = 1800
        c.KubeSpawner.http_timeout = 60

ray-cluster:
  image:
    tag: 2.41.0-py311-gpu
  common:
    containerEnv:
      - name: PYTHONPATH
        value: "/mnt/ray-storage/libraries"
      - name: TMPDIR
        value: "/mnt/ray-storage/temp"
  head:
    serviceType: ClusterIP
    resources:
      requests:
        cpu: "1"
        memory: "2G"
        ephemeral-storage: 10Gi
      limits:
        cpu: "4"
        memory: "8G"
        ephemeral-storage: 10Gi
    volumes:
    - name: ray-pvc-storage
      persistentVolumeClaim:
        claimName: "ai-starter-kit-models-cache-pvc"  # this value should'n be hardcoded. The actual value should be: {{ .Release.Name }}-models-cache-pvc
    volumeMounts:
      - name: ray-pvc-storage
        mountPath: /mnt/ray-storage
    podSecurityContext:
      fsGroup: 1000
  worker:
    resources:
      requests:
        cpu: "1"
        memory: "2G"
        ephemeral-storage: 10Gi
      limits:
        cpu: "4"
        memory: "8G"
        ephemeral-storage: 10Gi
    volumes:
    - name: ray-pvc-storage
      persistentVolumeClaim:
        claimName: "ai-starter-kit-models-cache-pvc"  # this value should'n be hardcoded. The actual value should be: {{ .Release.Name }}-models-cache-pvc
    volumeMounts:
      - name: ray-pvc-storage
        mountPath: /mnt/ray-storage
    podSecurityContext:
      fsGroup: 1000

huggingface:
  # Provide your Hugging Face token here to download gated or private models.
  # It is recommended to set this via --set or a separate values file, e.g.,
  # --set huggingface.token=hf_...
  token: ""

modelsCachePvc:
  enabled: true
  # To use the default StorageClass, set storageClassName to null or omit it.
  # To use a specific StorageClass (e.g. "standard-rwo" on GKE), provide its name.
  # To create a PVC that doesn't request any StorageClass, set it to an empty string ("").
  storageClassName: "standard-rwo"
  accessModes:
    - ReadWriteOnce
  size: 100Gi

localPersistence:
  # For local development with minikube, this allows persisting the models-cache
  # on the host machine, surviving `minikube stop/start`.
  # 1. Create a directory on your host: `mkdir -p /data/models-cache`
  # 2. Start minikube with the mount: `minikube start --mount --mount-string="/data/models-cache:/data/models-cache"`
  # 3. Set enabled to true below, or via `--set localPersistence.enabled=true`
  enabled: false
  # This path must match the destination path inside the minikube node.
  hostPath: "/tmp/models-cache"
